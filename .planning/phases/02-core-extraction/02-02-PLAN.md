---
phase: 02-core-extraction
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - pyproject.toml
  - src/dataset_generator/utils/fuzzy_matcher.py
  - src/dataset_generator/extraction/evidence_validator.py
autonomous: true

must_haves:
  truths:
    - "Evidence validation uses exact match first and falls back to fuzzy matching (RapidFuzz) with 90%+ similarity threshold"
    - "Every extracted use case and policy has evidence with verbatim quote matching source lines (exact or fuzzy)"
    - "System works on unseen inputs — pipeline succeeds on all 3 example documents without hardcoded assumptions"
  artifacts:
    - path: "pyproject.toml"
      provides: "RapidFuzz dependency declaration"
      contains: "rapidfuzz"
    - path: "src/dataset_generator/utils/fuzzy_matcher.py"
      provides: "Reusable fuzzy string matching utility with normalization"
      min_lines: 20
    - path: "src/dataset_generator/extraction/evidence_validator.py"
      provides: "Evidence validator with exact match + fuzzy fallback"
      contains: "fuzzy"
  key_links:
    - from: "src/dataset_generator/extraction/evidence_validator.py"
      to: "src/dataset_generator/utils/fuzzy_matcher.py"
      via: "imports fuzzy matching function"
      pattern: "from.*fuzzy_matcher import"
    - from: "src/dataset_generator/extraction/evidence_validator.py"
      to: "src/dataset_generator/extraction/markdown_parser.py"
      via: "uses ParsedMarkdown for source lines"
      pattern: "ParsedMarkdown"
---

<objective>
Add RapidFuzz-based fuzzy matching fallback to evidence validation and verify the complete extraction pipeline generalizes to unseen inputs.

Purpose: Enhanced prompts (from Plan 02-01) improve evidence accuracy, but LLMs still occasionally drop trailing whitespace, markdown formatting, or table pipe characters. Fuzzy matching at 90%+ threshold catches these near-misses without masking real prompt problems. Anti-hardcoding verification ensures the system works on diverse document structures (PIPE-06).

Output: Updated evidence_validator.py with fuzzy fallback, new fuzzy_matcher.py utility, RapidFuzz dependency, and verification results against all 3 example documents.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-extraction/02-RESEARCH.md
@.planning/phases/02-core-extraction/02-01-SUMMARY.md

@src/dataset_generator/extraction/evidence_validator.py
@src/dataset_generator/extraction/markdown_parser.py
@src/dataset_generator/utils/__init__.py
@src/dataset_generator/models/evidence.py
@src/dataset_generator/pipeline.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add RapidFuzz dependency and create fuzzy matching utility with evidence validator enhancement</name>
  <files>
    pyproject.toml
    src/dataset_generator/utils/fuzzy_matcher.py
    src/dataset_generator/extraction/evidence_validator.py
  </files>
  <action>
**Step 1: Add RapidFuzz to pyproject.toml**

Add `"rapidfuzz>=3.0"` to the `dependencies` list in pyproject.toml. Then run `pip install -e .` to install it.

**Step 2: Create src/dataset_generator/utils/fuzzy_matcher.py**

Create a reusable fuzzy matching utility module with:

```python
def normalize_for_comparison(text: str) -> str:
    """Normalize text for comparison: strip trailing whitespace per line, normalize line endings.

    Does NOT lowercase — preserves case for accurate matching.
    Does NOT strip leading whitespace — preserves indentation.
    """
    lines = text.replace('\r\n', '\n').replace('\r', '\n').split('\n')
    return '\n'.join(line.rstrip() for line in lines)


def fuzzy_match_score(text_a: str, text_b: str) -> float:
    """Return fuzzy similarity score (0-100) between two strings.

    Uses RapidFuzz fuzz.ratio for character-level comparison.
    Normalizes both inputs before comparison.

    Note: RapidFuzz 3.0+ does NOT auto-preprocess strings.
    We normalize explicitly before passing to fuzz.ratio.
    """
    from rapidfuzz import fuzz
    normalized_a = normalize_for_comparison(text_a)
    normalized_b = normalize_for_comparison(text_b)
    return fuzz.ratio(normalized_a, normalized_b)
```

**Step 3: Enhance evidence_validator.py with fuzzy fallback**

Modify `validate_evidence_quote()` to:
1. Add two new optional parameters: `enable_fuzzy: bool = True` and `fuzzy_threshold: float = 90.0`
2. Keep the existing exact match logic (normalize + compare) as the PRIMARY check
3. After exact match fails, if `enable_fuzzy=True`:
   - Import and call `fuzzy_match_score` from utils.fuzzy_matcher
   - If score >= `fuzzy_threshold`, return `(True, f"Fuzzy match ({score:.1f}% similarity)")`
   - If score < threshold, include the similarity score in the error message
4. If `enable_fuzzy=False` and exact match fails, return the existing error format

Replace the inline `normalize()` function with an import of `normalize_for_comparison` from `fuzzy_matcher` to avoid code duplication.

The `validate_all_evidence()` function should also accept and pass through `enable_fuzzy` and `fuzzy_threshold` parameters.

IMPORTANT: Per research pitfall guidance — exact match is ALWAYS tried first. Fuzzy matching is a fallback, not a replacement. Log messages should clearly indicate when fuzzy matching was used (the message parameter in the return tuple handles this).
  </action>
  <verify>
1. `pip install -e .` succeeds (RapidFuzz installs)
2. `python -c "from rapidfuzz import fuzz; print(f'RapidFuzz {fuzz.__module__} OK')"` — RapidFuzz importable
3. `python -c "from dataset_generator.utils.fuzzy_matcher import normalize_for_comparison, fuzzy_match_score; print(fuzzy_match_score('hello world', 'hello world'))"` — prints 100.0
4. `python -c "from dataset_generator.utils.fuzzy_matcher import fuzzy_match_score; print(fuzzy_match_score('| row |', '| row'))"` — prints a score > 80 (demonstrates fuzzy matching catches missing trailing pipe)
5. `python -c "from dataset_generator.extraction.evidence_validator import validate_evidence_quote; print('Import OK')"` — enhanced validator importable
  </verify>
  <done>
RapidFuzz added to pyproject.toml and installed. fuzzy_matcher.py utility provides normalize_for_comparison() and fuzzy_match_score() functions. evidence_validator.py uses exact match first, then fuzzy fallback at 90%+ threshold. validate_all_evidence passes through fuzzy parameters. Code deduplication: shared normalize function.
  </done>
</task>

<task type="auto">
  <name>Task 2: Anti-hardcoding verification against all 3 example documents</name>
  <files>
    src/dataset_generator/extraction/use_case_extractor.py
    src/dataset_generator/extraction/policy_extractor.py
  </files>
  <action>
Run the extraction pipeline against all 3 example documents to verify generalization (PIPE-06). This task verifies but does not modify source code unless issues are found.

**Step 1: Identify example documents**

```bash
ls *.md  # Find all example input markdown files
```

Expected: 3 files:
- example_input_raw_support_faq_and_tickets.md
- example_input_raw_operator_quality_checks.md
- example_input_raw_doctor_booking.md

**Step 2: Run pipeline on each document**

```bash
# Document 1: Support FAQ
python -m dataset_generator generate \
  --input example_input_raw_support_faq_and_tickets.md \
  --out /tmp/verify_02_support \
  --seed 42 --model gpt-4o-mini

# Document 2: Operator Quality
python -m dataset_generator generate \
  --input example_input_raw_operator_quality_checks.md \
  --out /tmp/verify_02_operator \
  --seed 42 --model gpt-4o-mini

# Document 3: Doctor Booking
python -m dataset_generator generate \
  --input example_input_raw_doctor_booking.md \
  --out /tmp/verify_02_booking \
  --seed 42 --model gpt-4o-mini
```

**Step 3: Verify results for each document**

For each output directory, check:
1. use_cases.json exists with 5+ use cases
2. policies.json exists with 5+ policies (2+ different types)
3. All IDs follow uc_/pol_ prefix conventions
4. Content is in Russian
5. Evidence validation passes (check pipeline log output for valid/invalid counts)
6. Evidence accuracy is 80%+ (target 90%+ with enhanced prompts + fuzzy matching)

**Step 4: Compare across documents**

Verify that accuracy does not vary by >20% across documents. If one document has significantly lower accuracy:
- Check if prompts have any document-specific assumptions
- Fix any discovered hardcoding in extractors (update files listed above)
- Re-run verification

**Step 5: Log results**

Record in SUMMARY:
- Per-document: use case count, policy count, evidence valid/invalid counts, policy type distribution
- Cross-document: accuracy consistency check

**If issues are found:** Fix prompt hardcoding in use_case_extractor.py or policy_extractor.py as needed. Common fixes: remove references to specific section headers, use generic pattern matching instructions, ensure table and prose handling both work.
  </action>
  <verify>
All 3 pipeline runs complete successfully (exit code 0). Each produces:
- use_cases.json with 5+ entries
- policies.json with 5+ entries with 2+ policy types
- Evidence validation showing 80%+ accuracy (ideally 90%+)
- No errors referencing missing sections or hardcoded assumptions
  </verify>
  <done>
Pipeline runs successfully on all 3 example documents (support FAQ, operator quality, doctor booking). Each produces 5+ use cases and 5+ policies with diverse type classification. Evidence accuracy is 80%+ across all documents. No hardcoded assumptions prevent generalization to unseen inputs.
  </done>
</task>

</tasks>

<verification>
1. RapidFuzz installed and importable: `python -c "from rapidfuzz import fuzz; print('OK')"`
2. Fuzzy matcher utility works: `python -c "from dataset_generator.utils.fuzzy_matcher import fuzzy_match_score; assert fuzzy_match_score('abc', 'abc') == 100.0; print('OK')"`
3. Evidence validator imports fuzzy_matcher: grep for "fuzzy_matcher" in evidence_validator.py
4. Pipeline succeeds on all 3 example documents without errors
5. Each document produces 5+ use cases and 5+ policies
6. Evidence accuracy is 80%+ on all documents (90%+ target)
7. Policy type distribution includes 2+ types per document
</verification>

<success_criteria>
- RapidFuzz integrated as dependency and used for evidence validation fallback
- Evidence validator tries exact match first, then fuzzy at 90%+ threshold
- Pipeline succeeds on example_input_raw_support_faq_and_tickets.md
- Pipeline succeeds on example_input_raw_operator_quality_checks.md
- Pipeline succeeds on example_input_raw_doctor_booking.md
- Each document produces 5+ use cases and 5+ policies
- Evidence accuracy ≥80% on all documents (≥90% target)
- No document-specific hardcoding in extraction prompts
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-extraction/02-02-SUMMARY.md`
</output>
