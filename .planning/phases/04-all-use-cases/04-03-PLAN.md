---
phase: 04-all-use-cases
plan: 03
type: execute
wave: 3
depends_on: ["04-01", "04-02"]
files_modified:
  - src/dataset_generator/generation/orchestrator.py
  - src/dataset_generator/generation/coverage.py
  - src/dataset_generator/pipeline.py
autonomous: true

must_haves:
  truths:
    - "Pipeline auto-detects case and formats from extracted use cases/policies without filename"
    - "Pipeline generates examples in ALL detected formats for a document"
    - "Operator quality documents produce BOTH single_utterance_correction AND dialog_last_turn_correction examples"
    - "Support bot documents produce examples with metadata.source across tickets, faq_paraphrase, and corner"
    - "Coverage enforcement validates format coverage (operator needs both) and source coverage (support needs all 3)"
    - "UseCase, Policy, and TestCase objects have case field populated after auto-detection"
    - "All output files match tz.md data contract structure"
    - "Pipeline works on any markdown document without hardcoded filenames"
  artifacts:
    - path: "src/dataset_generator/generation/orchestrator.py"
      provides: "Updated orchestrator with format-aware generation loop"
      exports: ["orchestrate_generation"]
    - path: "src/dataset_generator/generation/coverage.py"
      provides: "Extended coverage enforcement with format and source checks"
      exports: ["enforce_coverage", "enforce_format_coverage", "enforce_source_coverage"]
    - path: "src/dataset_generator/pipeline.py"
      provides: "Pipeline with case detection, multi-format generation, case field population"
      exports: ["run_pipeline"]
  key_links:
    - from: "src/dataset_generator/pipeline.py"
      to: "src/dataset_generator/generation/case_detector.py"
      via: "detect_case_and_formats called after extraction"
      pattern: "detect_case_and_formats"
    - from: "src/dataset_generator/generation/orchestrator.py"
      to: "src/dataset_generator/generation/format_adapters"
      via: "get_adapter_for_format in generation loop"
      pattern: "get_adapter_for_format"
    - from: "src/dataset_generator/generation/orchestrator.py"
      to: "src/dataset_generator/generation/variation_router.py"
      via: "generate_variations for test case parameters"
      pattern: "generate_variations"
    - from: "src/dataset_generator/generation/orchestrator.py"
      to: "src/dataset_generator/generation/source_classifier.py"
      via: "classify_source_type for support_bot examples"
      pattern: "classify_source_type"
    - from: "src/dataset_generator/generation/coverage.py"
      to: "enforce_format_coverage and enforce_source_coverage"
      via: "post-generation validation"
      pattern: "enforce_format_coverage|enforce_source_coverage"
---

<objective>
Wire case detection, format-specific generation, and enhanced coverage enforcement into the pipeline for universal multi-case support.

Purpose: The pipeline currently generates generic test cases and examples without case/format awareness. This plan connects the case detector, format adapters, variation router, and source classifier into the orchestration loop so the pipeline automatically detects what case it's processing, generates examples in ALL applicable formats, classifies metadata.source, and enforces coverage requirements — making it work universally on any document.

Output: Updated orchestrator with format-aware generation, enhanced coverage enforcement, pipeline with auto-detection
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-all-use-cases/04-CONTEXT.md
@.planning/phases/04-all-use-cases/04-RESEARCH.md
@.planning/phases/04-all-use-cases/04-01-SUMMARY.md
@.planning/phases/04-all-use-cases/04-02-SUMMARY.md
@tz.md
@src/dataset_generator/pipeline.py
@src/dataset_generator/generation/orchestrator.py
@src/dataset_generator/generation/coverage.py
@src/dataset_generator/cli.py
@src/dataset_generator/generation/case_detector.py
@src/dataset_generator/generation/format_adapters/__init__.py
@src/dataset_generator/generation/variation_router.py
@src/dataset_generator/generation/source_classifier.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite orchestrator for format-aware multi-format generation</name>
  <files>
    src/dataset_generator/generation/orchestrator.py
    src/dataset_generator/generation/coverage.py
  </files>
  <action>
**orchestrator.py — Major rewrite of orchestrate_generation:**

The current orchestrator routes between DeepEval/Ragas/Giskard frameworks via OpenAI function calling. This needs to be extended to:
1. Accept case and formats parameters
2. Use format adapters for generation instead of (or in addition to) framework generators
3. Use variation router for test case parameters
4. Classify metadata.source for support_bot

Update `orchestrate_generation` signature:
```python
def orchestrate_generation(
    use_case: UseCase,
    policies: list[Policy],
    document_path: str,
    model: str = "gpt-4o-mini",
    seed: int | None = None,
    min_test_cases: int = 3,
    case: str = "support_bot",          # NEW
    formats: list[str] | None = None,   # NEW
) -> tuple[list[TestCase], list[DatasetExample]]:
```

New generation flow:
1. Import and call `generate_variations(case, use_case.description, policies, min_test_cases)` to get parameter combinations
2. For each format in formats (iterate ALL detected formats):
   a. Get the appropriate adapter via `get_adapter_for_format(format, case)`
   b. For each parameter combination (test case):
      - Create a TestCase with: id (tc_ prefix), use_case_id, case, name (from use case + params), description, parameter_variation_axes (from variation router), parameters (the param dict), policy_ids (all policy ids), metadata with generator="format_adapter"
      - Call adapter.generate_example() to generate a DatasetExample
      - Set example.case = case
      - If case == "support_bot": call classify_source_type() and set metadata.source
      - Run adapter.validate_format() on the example and log any errors
      - Collect test_cases and examples
3. If format adapter generation fails for any test case, fall back to generate_with_openai_fallback with case and formats parameters
4. Still attempt the existing framework-based generation (DeepEval/Ragas/Giskard) as a SUPPLEMENTARY source — if framework results are available, adapt them and add. But format adapters are now the PRIMARY path.
5. The OpenAI function calling routing to frameworks is kept but made SECONDARY — first try format adapters, then supplement with frameworks if needed to meet min_test_cases.

IMPORTANT: Keep the existing _invoke_deepeval, _invoke_ragas, _invoke_giskard functions. They still work as supplementary generators. The key change is that format adapters are now the PRIMARY generation path, and framework generators supplement.

CRITICAL: Ensure that for operator_quality, the loop iterates BOTH formats (single_utterance_correction AND dialog_last_turn_correction), generating test cases and examples for each. This means the total test cases per use case will be roughly min_test_cases * len(formats).

**coverage.py — Add format and source coverage enforcement:**

Add two new functions:

```python
def enforce_format_coverage(examples: list[DatasetExample], case: str) -> list[str]:
    """Ensure all required formats are present for the case."""
```
- For operator_quality: requires both single_utterance_correction AND dialog_last_turn_correction
- For support_bot: requires single_turn_qa
- Returns list of warning strings for missing formats

```python
def enforce_source_coverage(examples: list[DatasetExample], case: str) -> list[str]:
    """Ensure all required metadata.source types are present."""
```
- For support_bot: requires tickets, faq_paraphrase, AND corner
- Returns list of warning strings for missing source types

Update the existing `enforce_coverage` function to call both new functions and include their warnings in the return value.
  </action>
  <verify>
Run: `python3 -c "
from dataset_generator.generation.orchestrator import orchestrate_generation
from dataset_generator.generation.coverage import enforce_format_coverage, enforce_source_coverage
import inspect
# Verify orchestrator accepts new params
sig = inspect.signature(orchestrate_generation)
assert 'case' in sig.parameters
assert 'formats' in sig.parameters
# Verify new coverage functions exist
assert callable(enforce_format_coverage)
assert callable(enforce_source_coverage)
# Test coverage functions with mock data
from dataset_generator.models.dataset_example import DatasetExample, InputData, Message
ex1 = DatasetExample(id='ex_001', case='operator_quality', format='single_utterance_correction', use_case_id='uc_001', test_case_id='tc_001', input=InputData(messages=[Message(role='operator', content='test')], target_message_index=0), expected_output='test', evaluation_criteria=['a','b','c'], policy_ids=['pol_001'])
warnings = enforce_format_coverage([ex1], 'operator_quality')
assert len(warnings) > 0  # Missing dialog_last_turn_correction
assert 'dialog_last_turn_correction' in warnings[0]
src_warnings = enforce_source_coverage([ex1], 'support_bot')
assert len(src_warnings) > 0  # Missing all source types
print('Orchestrator and coverage updates verified')
"` — should print 'Orchestrator and coverage updates verified'
  </verify>
  <done>Orchestrator uses format adapters as primary generation path with framework supplementation, coverage enforcement validates format and source distribution</done>
</task>

<task type="auto">
  <name>Task 2: Wire auto-detection into pipeline and populate case fields</name>
  <files>
    src/dataset_generator/pipeline.py
  </files>
  <action>
Update pipeline.py to:

1. **After Step 4 (evidence validation), add new Step 4.5: Auto-detect case and formats:**
   ```python
   # Step 4.5: Auto-detect case and formats
   from .generation.case_detector import detect_case_and_formats
   detection = detect_case_and_formats(use_case_list.use_cases, policy_list.policies, model=config.model)
   detected_case = detection.case
   detected_formats = detection.formats
   logger.info(f"Auto-detected case: {detected_case}, formats: {detected_formats}")
   ```

2. **After detection, populate case field on all extracted use cases and policies:**
   ```python
   # Populate case field on extracted artifacts
   for uc in use_case_list.use_cases:
       uc.case = detected_case
   for pol in policy_list.policies:
       pol.case = detected_case
   ```

3. **Update Step 5 (generation) to pass case and formats to orchestrate_generation:**
   ```python
   test_cases, examples = orchestrate_generation(
       use_case=use_case,
       policies=policy_list.policies,
       document_path=str(config.input_file),
       model=config.model,
       seed=config.seed,
       min_test_cases=config.n_test_cases_per_uc,
       case=detected_case,
       formats=detected_formats,
   )
   ```

4. **After Step 6 (referential integrity), add Step 6.5: Format and source coverage enforcement:**
   ```python
   from .generation.coverage import enforce_format_coverage, enforce_source_coverage
   format_warnings = enforce_format_coverage(all_examples, detected_case)
   source_warnings = enforce_source_coverage(all_examples, detected_case)
   for w in format_warnings + source_warnings:
       logger.warning(f"Coverage: {w}")
   ```

5. **Update the summary output to show detected case and formats:**
   ```python
   print(f"Case: {detected_case}")
   print(f"Formats: {', '.join(detected_formats)}")
   ```

6. **Update PipelineResult to include case and formats:**
   Add `case: str` and `formats: list[str]` fields to PipelineResult dataclass.

7. **IMPORTANT — do NOT break backward compatibility:**
   - If detection fails, default to case="support_bot", formats=["single_turn_qa"]
   - Wrap detection in try/except with clear warning

8. **Update run_manifest to include case and formats in metadata:**
   The RunManifest already has a flexible structure. Add detected_case and detected_formats to the manifest data.

9. **End-to-end verification commands to run after wiring:**
   After completing the code changes, run the pipeline on both inputs as a verification step:
   - `python -m dataset_generator generate --input example_input_raw_support_faq_and_tickets.md --out out/support --seed 42`
   - `python -m dataset_generator generate --input example_input_raw_operator_quality_checks.md --out out/operator_quality --seed 42`
   - Check that both produce all 5 output files
   - Check out/support/dataset.json has metadata.source with tickets, faq_paraphrase, corner values
   - Check out/operator_quality/dataset.json has examples with both single_utterance_correction and dialog_last_turn_correction formats and valid target_message_index
  </action>
  <verify>
Run: `python3 -c "
from dataset_generator.pipeline import PipelineConfig, PipelineResult, run_pipeline
import inspect
# Just verify the module imports without error
print('Pipeline module loads successfully')
"` — should print 'Pipeline module loads successfully'

Run: `python3 -c "
# Verify pipeline imports all new dependencies without errors
from dataset_generator.pipeline import run_pipeline
from dataset_generator.generation.case_detector import detect_case_and_formats
from dataset_generator.generation.orchestrator import orchestrate_generation
from dataset_generator.generation.coverage import enforce_format_coverage, enforce_source_coverage
from dataset_generator.generation.format_adapters import get_adapter_for_format
from dataset_generator.generation.variation_router import generate_variations
from dataset_generator.generation.source_classifier import classify_source_type
print('All pipeline dependencies importable')
"` — should print 'All pipeline dependencies importable'
  </verify>
  <done>Pipeline auto-detects case/formats, populates case fields on all artifacts, passes case/formats to orchestrator, enforces format and source coverage, includes case/formats in PipelineResult and run_manifest. Both mandatory inputs generate correct outputs with all required formats and source types.</done>
</task>

</tasks>

<verification>
1. Pipeline auto-detects support_bot from support FAQ input
2. Pipeline auto-detects operator_quality from operator quality input
3. Support bot generates single_turn_qa examples with 3 source types
4. Operator quality generates BOTH correction formats
5. dialog_last_turn_correction examples have correct target_message_index
6. Coverage enforcement warns on missing formats/sources
7. All output files have populated case fields
8. Pipeline works without hardcoded filename references
</verification>

<success_criteria>
- `python -m dataset_generator generate --input example_input_raw_support_faq_and_tickets.md --out out/support --seed 42` completes with 5+ use cases, 5+ policies, dataset with all 3 source types
- `python -m dataset_generator generate --input example_input_raw_operator_quality_checks.md --out out/operator_quality --seed 42` completes with both correction formats and correct target_message_index
- Both output directories contain all 5 files (use_cases.json, policies.json, test_cases.json, dataset.json, run_manifest.json)
- No hardcoded filename references in pipeline code
</success_criteria>

<output>
After completion, create `.planning/phases/04-all-use-cases/04-03-SUMMARY.md`
</output>
